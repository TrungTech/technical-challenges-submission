{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library and path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "DATA_FILE_PATH = \"test_data/data.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 46279 records.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    records = []\n",
    "    with open(DATA_FILE_PATH, 'r', encoding='utf-8') as f:\n",
    "        for line_number, line in enumerate(f):\n",
    "            try:\n",
    "                records.append(json.loads(line))\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON on line {line_number + 1}: {e}\")\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    print(f\"Successfully loaded {len(df)} records.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Data file not found at {DATA_FILE_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during data exploration: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Exploration and Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View basic info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46279 entries, 0 to 46278\n",
      "Data columns (total 43 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   sacc_items                46279 non-null  int64  \n",
      " 1   work_orders               46279 non-null  int64  \n",
      " 2   female_items              46279 non-null  int64  \n",
      " 3   is_newsletter_subscriber  46279 non-null  object \n",
      " 4   male_items                46279 non-null  int64  \n",
      " 5   afterpay_payments         46279 non-null  int64  \n",
      " 6   msite_orders              46279 non-null  int64  \n",
      " 7   wftw_items                46279 non-null  int64  \n",
      " 8   mapp_items                46279 non-null  int64  \n",
      " 9   orders                    46279 non-null  int64  \n",
      " 10  cc_payments               46279 non-null  int64  \n",
      " 11  curvy_items               46279 non-null  int64  \n",
      " 12  paypal_payments           46279 non-null  int64  \n",
      " 13  macc_items                46279 non-null  int64  \n",
      " 14  cancels                   46279 non-null  int64  \n",
      " 15  revenue                   46279 non-null  float64\n",
      " 16  returns                   46279 non-null  int64  \n",
      " 17  other_collection_orders   46279 non-null  int64  \n",
      " 18  parcelpoint_orders        46279 non-null  int64  \n",
      " 19  customer_id               46279 non-null  object \n",
      " 20  android_orders            46279 non-null  int64  \n",
      " 21  days_since_last_order     46279 non-null  int64  \n",
      " 22  vouchers                  46279 non-null  int64  \n",
      " 23  average_discount_used     46279 non-null  float64\n",
      " 24  shipping_addresses        46279 non-null  int64  \n",
      " 25  redpen_discount_used      46279 non-null  float64\n",
      " 26  mftw_items                46279 non-null  int64  \n",
      " 27  days_since_first_order    46279 non-null  int64  \n",
      " 28  unisex_items              46279 non-null  int64  \n",
      " 29  home_orders               46279 non-null  int64  \n",
      " 30  coupon_discount_applied   36074 non-null  float64\n",
      " 31  desktop_orders            46279 non-null  int64  \n",
      " 32  ios_orders                46279 non-null  int64  \n",
      " 33  apple_payments            46279 non-null  int64  \n",
      " 34  wspt_items                46279 non-null  int64  \n",
      " 35  wacc_items                46279 non-null  int64  \n",
      " 36  items                     46279 non-null  int64  \n",
      " 37  mspt_items                46279 non-null  int64  \n",
      " 38  devices                   46279 non-null  int64  \n",
      " 39  different_addresses       46279 non-null  int64  \n",
      " 40  wapp_items                46279 non-null  int64  \n",
      " 41  other_device_orders       46279 non-null  int64  \n",
      " 42  average_discount_onoffer  46279 non-null  float64\n",
      "dtypes: float64(5), int64(36), object(2)\n",
      "memory usage: 15.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBSERVATION**:\n",
    "- Dataset contain `46279` rows and `43` columns\n",
    "- Column `coupon_discount_applied` have 46279 - 36074 = `10205` null value\n",
    "\n",
    "**ACTION**:\n",
    "- Fill null values in `coupon_discount_applied` column with 0 since missing values likely indicate no discount was applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get descriptive statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_TYPES = {\n",
    "    'integer': df.select_dtypes(include=['int64', 'Int64']).columns.tolist(),\n",
    "    'float': df.select_dtypes(include=['float64']).columns.tolist(),\n",
    "    'string': df.select_dtypes(include=['object', 'string']).columns.tolist()\n",
    "}\n",
    "\n",
    "integer_columns = COLUMN_TYPES['integer']\n",
    "float_columns = COLUMN_TYPES['float']\n",
    "string_columns = COLUMN_TYPES['string']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Descriptive Statistics for Integer Columns ---\n",
      "       sacc_items  work_orders  female_items  male_items  afterpay_payments  \\\n",
      "count    46279.00     46279.00      46279.00    46279.00           46279.00   \n",
      "mean         0.09         0.24          6.47        1.72               0.05   \n",
      "min          0.00         0.00          0.00        0.00               0.00   \n",
      "max         29.00        84.00        537.00      273.00               1.00   \n",
      "\n",
      "       msite_orders  wftw_items  mapp_items    orders  cc_payments  \\\n",
      "count      46279.00    46279.00    46279.00  46279.00     46279.00   \n",
      "mean           0.98        1.63        0.93      4.11         0.64   \n",
      "min            0.00        0.00        0.00      1.00         0.00   \n",
      "max          172.00      261.00      151.00    665.00         1.00   \n",
      "\n",
      "       curvy_items  paypal_payments  macc_items   cancels   returns  \\\n",
      "count     46279.00         46279.00    46279.00  46279.00  46279.00   \n",
      "mean          0.04             0.49        0.57      0.05      1.62   \n",
      "min           0.00             0.00        0.00      0.00      0.00   \n",
      "max         116.00             1.00      353.00    460.00    343.00   \n",
      "\n",
      "       other_collection_orders  parcelpoint_orders  android_orders  \\\n",
      "count                 46279.00            46279.00        46279.00   \n",
      "mean                      2.31                0.03            0.04   \n",
      "min                       0.00                0.00            0.00   \n",
      "max                     665.00               32.00           33.00   \n",
      "\n",
      "       days_since_last_order  vouchers  shipping_addresses  mftw_items  \\\n",
      "count               46279.00  46279.00             46279.0    46279.00   \n",
      "mean                24592.68      0.94                 1.5        0.42   \n",
      "min                    24.00      0.00                 1.0        0.00   \n",
      "max                 51840.00     57.00                15.0       78.00   \n",
      "\n",
      "       days_since_first_order  unisex_items  home_orders  desktop_orders  \\\n",
      "count                46279.00      46279.00     46279.00        46279.00   \n",
      "mean                  1374.04          0.39         1.53            2.62   \n",
      "min                      1.00          0.00         0.00            0.00   \n",
      "max                   2164.00         83.00       175.00          665.00   \n",
      "\n",
      "       ios_orders  apple_payments  wspt_items  wacc_items     items  \\\n",
      "count    46279.00         46279.0    46279.00    46279.00  46279.00   \n",
      "mean         0.46             0.0        0.38        0.57      8.58   \n",
      "min          0.00             0.0        0.00        0.00      1.00   \n",
      "max         84.00             1.0       56.00      353.00    701.00   \n",
      "\n",
      "       mspt_items   devices  different_addresses  wapp_items  \\\n",
      "count    46279.00  46279.00             46279.00     46279.0   \n",
      "mean         0.12      1.28                 0.12         3.8   \n",
      "min          0.00      1.00                 0.00         0.0   \n",
      "max         38.00      3.00                 1.00       409.0   \n",
      "\n",
      "       other_device_orders  \n",
      "count              46279.0  \n",
      "mean                   0.0  \n",
      "min                    0.0  \n",
      "max                    2.0  \n",
      "--- Descriptive Statistics for Float Columns ---\n",
      "         revenue  average_discount_used  redpen_discount_used  \\\n",
      "count   46279.00               46279.00              46279.00   \n",
      "mean     1303.70                2357.38                435.22   \n",
      "min         0.00                   0.00                  0.00   \n",
      "max    354700.16               10000.00             102653.77   \n",
      "\n",
      "       coupon_discount_applied  average_discount_onoffer  \n",
      "count                 36074.00                  46279.00  \n",
      "mean                    174.40                      0.19  \n",
      "min                       0.00                      0.00  \n",
      "max                   33332.26                      1.00  \n",
      "--- Descriptive Statistics for String Columns ---\n",
      "         is_newsletter_subscriber  customer_id\n",
      "count                       46279        46279\n",
      "nunique                         2        46030\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Descriptive Statistics for Integer Columns ---\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(df[integer_columns].agg(['count', 'mean', 'min', 'max']).round(2))\n",
    "pd.reset_option('display.max_columns')\n",
    "\n",
    "print(\"--- Descriptive Statistics for Float Columns ---\")\n",
    "print(df[float_columns].agg(['count', 'mean', 'min', 'max']).round(2))\n",
    "\n",
    "print(\"--- Descriptive Statistics for String Columns ---\")\n",
    "print(df[string_columns].agg(['count', 'nunique']).round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBSERVATION**:\n",
    "\n",
    "**Integer Columns Analysis:**\n",
    "\n",
    "1.  **`days_since_last_order`**:\n",
    "    *   The `mean` value is approximately `24592.68` days (around 67.3 years) and the `max` is `51840` days (around 142 years). These values are implausibly high for \"days since last order\" and strongly suggest this column is corrupted or its unit is not days (e.g., it might be hours, minutes, or has an erroneous scaling factor).\n",
    "    *   This contrasts sharply with `days_since_first_order` (mean ~3.7 years), which appears more reasonable.\n",
    "    *   **This is a primary candidate for a corrupted column.**\n",
    "\n",
    "2.  **Payment Columns & `different_addresses`**:\n",
    "    *   Columns like `cc_payments`, `paypal_payments`, `afterpay_payments`, `apple_payments`, and `different_addresses` all have a `max` value of `1`.\n",
    "    *   This suggests they might be acting as boolean flags (0 or 1 indicating presence/absence) rather than \"Number of times...\" as per some column descriptions. If they are indeed counts, a max of 1 for all customers is highly unlikely for active payment methods. This needs clarification.\n",
    "\n",
    "3.  **Order Aggregation Columns**:\n",
    "    *   `other_collection_orders` and `desktop_orders` have a `max` value of `665`, which is identical to the `max` value for the `orders` column. This implies that for at least one customer, *all* their orders (665 of them) were either \"other collection\" or \"desktop\" orders. While possible, this warrants a consistency check at the record level to ensure that the sum of order channels/destinations matches total `orders` for each customer.\n",
    "\n",
    "4.  **General Counts**:\n",
    "    *   `orders` and `items` both have a `min` of `1`. This indicates that every record in this dataset pertains to a customer who has made at least one order and purchased at least one item.\n",
    "    *   Other item counts (e.g., `female_items`, `male_items`) and activity counts (e.g., `cancels`, `returns`) have plausible ranges, but their consistency with total `orders` and `items` should be verified\n",
    "\n",
    "**Float Columns Analysis:**\n",
    "\n",
    "1.  **`revenue`**:\n",
    "    *   The `min` is `0.00`, which is plausible (e.g., all items returned, or initial order not yet fully processed/paid). The `max` is `354700.16`, showing a wide range of customer spending.\n",
    "    *   The presence of zero revenue cases requires further investigation to understand if these represent returns, cancelled orders, or data quality issues\n",
    "\n",
    "**String Columns Analysis:**\n",
    "\n",
    "1.  **`customer_id`**:\n",
    "    *   The `count` is `46279`, but `nunique` (number of unique values) is `46030`.\n",
    "    *   This indicates there are **`249` duplicate `customer_id` values**. This is a critical data quality issue that needs to be addressed, as customer IDs should uniquely identify customers.\n",
    "\n",
    "2.  **`is_newsletter_subscriber`**:\n",
    "    *   `nunique` is `2`. This suggests the column has been successfully processed into two distinct categories.\n",
    "\n",
    "**Summary & Next Steps:**\n",
    "\n",
    "*   **Corrupted Columns Candidates:** `days_since_last_order` show strong signs of corruption or systemic error.\n",
    "*   **Data Definition Mismatch:** Payment-related columns and `different_addresses` might be boolean flags rather than counts.\n",
    "*   **Duplicate Customer IDs:** The presence of 249 duplicate `customer_id`s must be investigated and resolved.\n",
    "*   **Order Channel Validation:** Need to verify that total `orders` equals the sum of all order channel counts (e.g., `desktop_orders` + `mobile_orders` + `app_orders`) for each customer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data & Handle corrupted/abnormal columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle missing values by fill with 0 and convert data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Columzn 'coupon_discount_applied' has 10205 NaN values.\n"
     ]
    }
   ],
   "source": [
    "def convert_column_type(df: pd.DataFrame, cols: list[str], dtype: str) -> None:\n",
    "    \"\"\"\n",
    "    Convert column to specified data type, handling NaN values and printing warnings.\n",
    "    \n",
    "    Args:\n",
    "        df: pandas DataFrame\n",
    "        cols: list of column names to convert\n",
    "        dtype: data type to convert to ('int', 'float', or 'str')\n",
    "    \"\"\"\n",
    "    for col in cols:\n",
    "        if col in df.columns:\n",
    "            if dtype in ['int', 'float']:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                \n",
    "                nan_count = df[col].isna().sum()\n",
    "                if nan_count > 0:\n",
    "                    print(f\"Warning: Columzn '{col}' has {nan_count} NaN values.\")\n",
    "                \n",
    "                df[col] = df[col].fillna(0)\n",
    "                df[col] = df[col].astype(dtype)\n",
    "            \n",
    "            elif dtype == 'str':\n",
    "                df[col] = df[col].astype(str)\n",
    "\n",
    "convert_column_type(df, integer_columns, 'int') \n",
    "convert_column_type(df, float_columns, 'float')   \n",
    "convert_column_type(df, string_columns, 'str')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle duplicate `customer_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 498 duplicate customer_id records\n",
      "Number of unique customer_ids with multiple records: 249\n",
      "Look like each record duplicate two times\n"
     ]
    }
   ],
   "source": [
    "duplicate_records = df[df.duplicated(subset=['customer_id'], keep=False)]\n",
    "num_duplicates = len(duplicate_records)\n",
    "\n",
    "print(f\"Found {num_duplicates} duplicate customer_id records\")\n",
    "\n",
    "# Get counts of each duplicated customer_id\n",
    "dup_counts = df['customer_id'].value_counts()\n",
    "duplicate_customer_ids = dup_counts[dup_counts > 1]\n",
    "\n",
    "print(f\"Number of unique customer_ids with multiple records: {len(duplicate_customer_ids)}\")\n",
    "\n",
    "print('Look like each record duplicate two times')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check if all duplicates appear exactly twice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each duplicated customer_id appears exactly twice in the dataset\n"
     ]
    }
   ],
   "source": [
    "is_all_duplicates_twice = all(count == 2 for count in duplicate_customer_ids)\n",
    "if is_all_duplicates_twice:\n",
    "    print('Each duplicated customer_id appears exactly twice in the dataset')\n",
    "else:\n",
    "    print('Duplicate patterns:')\n",
    "    print(duplicate_customer_ids.value_counts().to_frame('count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check values are identical in all other columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All values are consistent across duplicate records\n"
     ]
    }
   ],
   "source": [
    "columns = integer_columns + float_columns + string_columns\n",
    "inconsistent_duplicates_count = 0\n",
    "\n",
    "for customer_id, _ in duplicate_customer_ids.items():\n",
    "    customer_records = duplicate_records[duplicate_records['customer_id'] == customer_id]\n",
    "    \n",
    "    # Check if values are identical across duplicates\n",
    "    for col in columns:\n",
    "        if not customer_records[col].nunique() == 1:\n",
    "            inconsistent_duplicates_count += 1\n",
    "    \n",
    "\n",
    "if inconsistent_duplicates_count > 0:\n",
    "    print(f\"Found {inconsistent_duplicates_count} inconsistent values across duplicate records\")\n",
    "else:\n",
    "    print(\"All values are consistent across duplicate records\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Safely remove the redundant recors, keeping only one instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['customer_id'], keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix cases where `days_since_last_order` exceeds `days_since_first_order`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 43365 records where 'days_since_last_order' > 'days_since_first_order'.\n"
     ]
    }
   ],
   "source": [
    "if 'days_since_first_order' in df.columns and 'days_since_last_order' in df.columns:\n",
    "    inconsistent_days = df[df['days_since_last_order'] > df['days_since_first_order']]\n",
    "    if not inconsistent_days.empty:\n",
    "        print(f\"There are {len(inconsistent_days)} records where 'days_since_last_order' > 'days_since_first_order'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of difference between dates:\n",
      "Minimum difference: 1 days\n",
      "Maximum difference: 49680 days\n",
      "Mean difference: 24638.7 days\n"
     ]
    }
   ],
   "source": [
    "date_difference = inconsistent_days['days_since_last_order'] - inconsistent_days['days_since_first_order']\n",
    "print(f\"Range of difference between dates:\")\n",
    "print(f\"Minimum difference: {date_difference.min():.0f} days\")\n",
    "print(f\"Maximum difference: {date_difference.max():.0f} days\")\n",
    "print(f\"Mean difference: {date_difference.mean():.1f} days\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBSERVATION**:\n",
    "- The range of differences between `days_since_last_order` and `days_since_first_order` is quite large. \n",
    "- This suggests these values may have been accidentally swapped during data entry. \n",
    "\n",
    "**ACTION**:\n",
    "- I will swap them back to maintain logical order where last_order >= first_order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 records where 'days_since_last_order' > 'days_since_first_order'.\n"
     ]
    }
   ],
   "source": [
    "#Create a mask for records where days_since_last_order > days_since_first_order\n",
    "swap_mask = df['days_since_last_order'] > df['days_since_first_order']\n",
    "\n",
    "# Swap the values using a temporary column\n",
    "df.loc[swap_mask, 'temp'] = df.loc[swap_mask, 'days_since_first_order']\n",
    "df.loc[swap_mask, 'days_since_first_order'] = df.loc[swap_mask, 'days_since_last_order']\n",
    "df.loc[swap_mask, 'days_since_last_order'] = df.loc[swap_mask, 'temp']\n",
    "\n",
    "# Drop the temporary column\n",
    "df.drop(columns=['temp'], inplace=True)\n",
    "\n",
    "# Check again\n",
    "inconsistent_days = df[df['days_since_last_order'] > df['days_since_first_order']]\n",
    "if inconsistent_days.empty:\n",
    "    print(f\"There are {len(inconsistent_days)} records where 'days_since_last_order' > 'days_since_first_order'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check consistency of Item Categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check consistency between items and gender categories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No inconsistencies found between 'items' and sum of gender categories\n"
     ]
    }
   ],
   "source": [
    "item_categories = ['female_items', 'male_items', 'unisex_items']\n",
    "if all(col in df.columns for col in item_categories + ['items']):\n",
    "    df['sum_item_categories'] = df[item_categories].sum(axis=1, skipna=False)\n",
    "    inconsistent_items_sum = df[df['items'] != df['sum_item_categories']]\n",
    "    inconsistent_items_sum = inconsistent_items_sum[\n",
    "        inconsistent_items_sum['items'].notna() & \n",
    "        inconsistent_items_sum['sum_item_categories'].notna()\n",
    "    ]\n",
    "    \n",
    "    if not inconsistent_items_sum.empty:\n",
    "        print(f\"Found {len(inconsistent_items_sum)} records where 'items' != sum of gender categories\")\n",
    "        \n",
    "        # Check if items is greater than sum of gender categories\n",
    "        items_greater = inconsistent_items_sum[\n",
    "            inconsistent_items_sum['items'] > inconsistent_items_sum['sum_item_categories']\n",
    "        ]\n",
    "        if not items_greater.empty:\n",
    "            print(f\"  - {len(items_greater)} records where 'items' > sum of gender categories\")\n",
    "            \n",
    "        # Check if items is less than sum of gender categories  \n",
    "        items_lesser = inconsistent_items_sum[\n",
    "            inconsistent_items_sum['items'] < inconsistent_items_sum['sum_item_categories']\n",
    "        ]\n",
    "        if not items_lesser.empty:\n",
    "            print(f\"  - {len(items_lesser)} records where 'items' < sum of gender categories\")\n",
    "    else:\n",
    "        print(\"No inconsistencies found between 'items' and sum of gender categories\")\n",
    "        \n",
    "    df.drop(columns=['sum_item_categories'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check consistency between items and detail categories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There are 16970 records where 'items' != sum of all detailed item category columns.\n",
      "    - 8240 records where 'items' > sum of detailed items\n",
      "    - 8730 records where 'items' < sum of detailed items\n"
     ]
    }
   ],
   "source": [
    "def check_item_categories(df: pd.DataFrame, detailed_item_cols: list[str]) -> None:\n",
    "        if all(col in df.columns for col in detailed_item_cols + ['items']):\n",
    "                df['sum_detailed_items'] = df[detailed_item_cols].sum(axis=1, skipna=False)\n",
    "                inconsistent_detailed_items_sum = df[df['items'] != df['sum_detailed_items']]\n",
    "                inconsistent_detailed_items_sum = inconsistent_detailed_items_sum[inconsistent_detailed_items_sum['items'].notna() & inconsistent_detailed_items_sum['sum_detailed_items'].notna()]\n",
    "\n",
    "                if not inconsistent_detailed_items_sum.empty:\n",
    "                        print(f\" There are {len(inconsistent_detailed_items_sum)} records where 'items' != sum of all detailed item category columns.\")\n",
    "                        \n",
    "                        # Check if items is greater than sum_detailed_items\n",
    "                        items_greater = inconsistent_detailed_items_sum[inconsistent_detailed_items_sum['items'] > inconsistent_detailed_items_sum['sum_detailed_items']]\n",
    "                        if not items_greater.empty:\n",
    "                                print(f\"    - {len(items_greater)} records where 'items' > sum of detailed items\")\n",
    "                        \n",
    "                        # Check if items is less than sum_detailed_items    \n",
    "                        items_lesser = inconsistent_detailed_items_sum[inconsistent_detailed_items_sum['items'] < inconsistent_detailed_items_sum['sum_detailed_items']]\n",
    "                        if not items_lesser.empty:\n",
    "                                print(f\"    - {len(items_lesser)} records where 'items' < sum of detailed items\")\n",
    "                else:\n",
    "                        print(f\"No records where 'items' != sum of all detailed item category columns.\")\n",
    "                df.drop(columns=['sum_detailed_items'], inplace=True)\n",
    "\n",
    "detailed_item_cols = ['wapp_items', 'wftw_items', 'mapp_items', 'wacc_items', 'macc_items', \n",
    "                        'mftw_items', 'wspt_items', 'mspt_items', 'curvy_items', 'sacc_items']\n",
    "check_item_categories(df, detailed_item_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBSERVATION**:\n",
    "- Case `items` < `sum_detailed_items`:\n",
    "\n",
    "    I assume that the `items` total is incorrectly calculated \n",
    "    \n",
    "\n",
    "- Case `items` > `sum_detailed_items`:\n",
    "\n",
    "    I assume that there are other categories of items not listed that contribute to the total\n",
    "    \n",
    "**ACTION**: \n",
    "I notice there are inconsistencies between `items` and sum of detailed item categories.\n",
    "However, I cannot definitively resolve these discrepancies without additional business rules and validation criteria:\n",
    "- When `items` < sum of detailed items: Need business rules to determine if `items` total is incorrect or if there's double-counting in detailed categories\n",
    "- When `items` > sum of detailed items: Need to confirm if missing categories exist or if `items` total includes items not tracked in detailed breakdown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to 'cleaned_data.csv'\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('test_data/cleaned_data.csv', index=False)\n",
    "print(\"Data saved successfully to 'cleaned_data.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
